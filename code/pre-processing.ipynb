{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_images = []\n",
    "flood_image_path = '../dataset/dataset/flooded/'\n",
    "for i in range(0, 461):\n",
    "    flood_images.append(cv.imread(f'{flood_image_path}{i}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_flood_images = []\n",
    "non_flood_images_2 = []\n",
    "non_flood_image_path = '../dataset/dataset/non-flooded/'\n",
    "for i in range(578, 904):\n",
    "    non_flood_images.append(cv.imread(f'{non_flood_image_path}{i}.jpg'))\n",
    "for i in range(904, 1039):\n",
    "    non_flood_images_2.append(cv.imread(f'{non_flood_image_path}{i}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood Images: 461\n",
      "Non-Flood Images: 326\n",
      "Non-Flood Images_2: 135\n",
      "Flood Images: (1503, 1509, 3)\n",
      "Non-Flood Images: (3000, 4000, 3)\n"
     ]
    }
   ],
   "source": [
    "# show the first flood image\n",
    "cv.imshow('Flood Image', flood_images[0])\n",
    "cv.waitKey(0)\n",
    "# show the first non-flood image\n",
    "cv.imshow('Non-Flood Image', non_flood_images[0])\n",
    "cv.waitKey(0)\n",
    "cv.imshow('Non-Flood Image_2', non_flood_images_2[0])\n",
    "cv.waitKey(0)\n",
    "# show size of flood and non-flood images\n",
    "print(f'Flood Images: {len(flood_images)}')\n",
    "print(f'Non-Flood Images: {len(non_flood_images)}')\n",
    "print(f'Non-Flood Images_2: {len(non_flood_images_2)}')\n",
    "# show size of flood and non-flood images\n",
    "print(f'Flood Images: {flood_images[0].shape}')\n",
    "print(f'Non-Flood Images: {non_flood_images[0].shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resize images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood Images: (461, 256, 256, 3)\n",
      "Non-Flood Images: (461, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "flood_images_resized = []\n",
    "for image in flood_images:\n",
    "    flood_images_resized.append(cv.resize(image, (256, 256)))\n",
    "non_flood_images_resized = []\n",
    "for image in non_flood_images:\n",
    "    non_flood_images_resized.append(cv.resize(image, (256, 256)))\n",
    "non_flood_images_resized_2 = []\n",
    "for image in non_flood_images_2:\n",
    "    non_flood_images_resized_2.append(cv.resize(image, (256, 256)))\n",
    "# chage flood list to numpy array\n",
    "flood_images_resized = np.array(flood_images_resized)\n",
    "# chage non-flood list after concatenating with non-flood_2 list to numpy array\n",
    "non_flood_images_resized = np.array(non_flood_images_resized + non_flood_images_resized_2)\n",
    "# show size of flood and non-flood images\n",
    "print(f'Flood Images: {flood_images_resized.shape}')\n",
    "print(f'Non-Flood Images: {non_flood_images_resized.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the resized images using numpy\n",
    "np.save('../dataset/dataset/flooded_resized.npy', flood_images_resized)\n",
    "np.save('../dataset/dataset/non-flooded_resized.npy', non_flood_images_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the resized images using numpy\n",
    "# flood_images_resized = np.load('../dataset/dataset/flooded_resized.npy')\n",
    "# non_flood_images_resized = np.load('../dataset/dataset/non-flooded_resized.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove noise from flood images\n",
    "flood_images_resized_blur = []\n",
    "for image in flood_images_resized:\n",
    "    flood_images_resized_blur.append(cv.medianBlur(image, 1))\n",
    "# remove noise from non-flood images\n",
    "non_flood_images_resized_blur = []\n",
    "for image in non_flood_images_resized:\n",
    "    non_flood_images_resized_blur.append(cv.medianBlur(image, 1))\n",
    "# show the first flood image\n",
    "cv.imshow('Flood Image', flood_images_resized_blur[0])\n",
    "cv.waitKey(0)\n",
    "# show the first non-flood image\n",
    "cv.imshow('Non-Flood Image', non_flood_images_resized_blur[0])\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the resized images using numpy\n",
    "np.save('../dataset/dataset/flooded_resized_blur.npy', flood_images_resized_blur)\n",
    "np.save('../dataset/dataset/non-flooded_resized_blur.npy', non_flood_images_resized_blur)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
