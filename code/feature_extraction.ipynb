{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the resized images using numpy\n",
    "flood_images_resized_blur = np.load('../dataset/dataset/flooded_resized_blur.npy')\n",
    "non_flood_images_resized_blur = np.load('../dataset/dataset/non-flooded_resized_blur.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(461, 256, 256, 3)\n",
      "(461, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the numpy images \n",
    "print(flood_images_resized_blur.shape)\n",
    "print(non_flood_images_resized_blur.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feauture Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harris Corner Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use Harris Corner Detection to extract features from the images\n",
    "# def harris_corner_detection(img):\n",
    "#     gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     gray = np.float32(gray)\n",
    "#     dst = cv.cornerHarris(gray, 2, 3, 0.04)\n",
    "#     dst = cv.dilate(dst, None)\n",
    "#     ret, dst = cv.threshold(dst, 0.01*dst.max(), 255, 0)\n",
    "#     dst = np.uint8(dst)\n",
    "#     ret, labels, stats, centroids = cv.connectedComponentsWithStats(dst)\n",
    "#     criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "#     corners = cv.cornerSubPix(gray, np.float32(centroids), (5, 5), (-1, -1), criteria)\n",
    "#     # flatten corners\n",
    "#     corners = corners.flatten()\n",
    "#     print(corners.shape)\n",
    "#     return corners\n",
    "\n",
    "# # extract the features from the images\n",
    "# flood_features = []\n",
    "# non_flood_features = []\n",
    "# for i in range(len(flood_images_resized_blur)):\n",
    "#     flood_features.append(harris_corner_detection(flood_images_resized_blur[i]))\n",
    "#     break\n",
    "# for i in range(len(non_flood_images_resized_blur)):\n",
    "#     non_flood_features.append(harris_corner_detection(non_flood_images_resized_blur[i]))\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sift**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use sift to extract features from the images\n",
    "# def sift(img):\n",
    "#     gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     sift = cv.SIFT_create()\n",
    "#     kp, des = sift.detectAndCompute(gray, None)\n",
    "#     # flatten des\n",
    "#     #des = des.flatten()\n",
    "#     print(des.shape)\n",
    "#     return des\n",
    "\n",
    "# # extract the features from the images\n",
    "# flood_features = []\n",
    "# non_flood_features = []\n",
    "# for i in range(len(flood_images_resized_blur)):\n",
    "#     flood_features.append(sift(flood_images_resized_blur[i]))\n",
    "#     break\n",
    "# for i in range(len(non_flood_images_resized_blur)):\n",
    "#     non_flood_features.append(sift(non_flood_images_resized_blur[i]))\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**orb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use orb to extract features from the images  \n",
    "# def surf(img):\n",
    "#     gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     orb = cv.ORB_create()\n",
    "#     kp, des = orb.detectAndCompute(gray, None)\n",
    "#     # flatten des\n",
    "#     #des = des.flatten()\n",
    "#     print(des.shape)\n",
    "#     return des\n",
    "\n",
    "# # extract the features from the images\n",
    "# flood_features = []\n",
    "# non_flood_features = []\n",
    "# for i in range(len(flood_images_resized_blur)):\n",
    "#     flood_features.append(surf(flood_images_resized_blur[i]))\n",
    "#     break\n",
    "# for i in range(len(non_flood_images_resized_blur)):\n",
    "#     non_flood_features.append(surf(non_flood_images_resized_blur[i]))\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram of Oriented Gradients (HOG)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606500,)\n",
      "(1606500,)\n",
      "(1606500,)\n",
      "(1606500,)\n",
      "(2, 1606500)\n",
      "(2, 1606500)\n"
     ]
    }
   ],
   "source": [
    "# use Histogram of Oriented Gradients (HOG) to extract features from the images\n",
    "\n",
    "\n",
    "def hog(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # winSize = (128,128)\n",
    "    # blockSize = (32,32)\n",
    "    # blockStride = (16,16)\n",
    "    # cellSize = (16,16)\n",
    "    # nbins = 9\n",
    "    hog = cv.HOGDescriptor()#winSize, blockSize, blockStride, cellSize, nbins)\n",
    "    h = hog.compute(gray)\n",
    "    print(h.shape)\n",
    "    return h\n",
    "\n",
    "# extract the features from the images\n",
    "flood_features_hog = []\n",
    "flood_features_hog_2 = []\n",
    "non_flood_features_hog = []\n",
    "non_flood_features_hog_2 = []\n",
    "for i in range(256):\n",
    "    flood_features_hog.append(hog(flood_images_resized_blur[i]))\n",
    "    break\n",
    "\n",
    "for i in range(256, len(non_flood_images_resized_blur)):\n",
    "    flood_features_hog_2.append(hog(flood_images_resized_blur[i]))\n",
    "    break\n",
    "\n",
    "for i in range(256):\n",
    "    non_flood_features_hog.append(hog(non_flood_images_resized_blur[i]))\n",
    "    break\n",
    "\n",
    "for i in range(256, len(non_flood_images_resized_blur)):\n",
    "    non_flood_features_hog_2.append(hog(non_flood_images_resized_blur[i]))\n",
    "    break  \n",
    "\n",
    "# turn the features into numpy arrays\n",
    "flood_features_hog = np.array(flood_features_hog + flood_features_hog_2)\n",
    "non_flood_features_hog = np.array(non_flood_features_hog + non_flood_features_hog_2)\n",
    "\n",
    "# print the shape of the numpy arrays\n",
    "print(flood_features_hog.shape)\n",
    "print(non_flood_features_hog.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the features to numpy files\n",
    "np.save('../dataset/dataset/flooded_features_hog.npy', flood_features_hog)\n",
    "np.save('../dataset/dataset/non-flooded_features_hog.npy', non_flood_features_hog)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Binary Patterns (LBP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "# use Local Binary Patterns (LBP). to extract features from the images using skimage\n",
    "def lbp_skimage(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    lbp = feature.local_binary_pattern(gray, 24, 8, method=\"uniform\")\n",
    "    # print(lbp.shape)\n",
    "    return lbp\n",
    "\n",
    "# extract the features from the images\n",
    "flood_features_lbp = []\n",
    "non_flood_features_lbp = []\n",
    "for i in range(len(flood_images_resized_blur)):\n",
    "    flood_features_lbp.append(lbp_skimage(flood_images_resized_blur[i]))\n",
    "for i in range(len(non_flood_images_resized_blur)):\n",
    "    non_flood_features_lbp.append(lbp_skimage(non_flood_images_resized_blur[i]))\n",
    "\n",
    "print(flood_features_lbp[0].shape)\n",
    "print(non_flood_features_lbp[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the features to numpy files\n",
    "np.save('../dataset/dataset/flooded_features_lbp.npy', flood_features_lbp)\n",
    "np.save('../dataset/dataset/non-flooded_features_lbp.npy', non_flood_features_lbp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
